## ESSLLI 2024 Course on Large Language Models, Knowledge, and Reasoning - Generative AI and Symbolic Knowledge Representations

(C) 2024 by [Damir Cavar] and [Billy Dickson](https://dickson.ai)

**Content License:** [CC BY-SA 4.0 Deed - Attribution-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-sa/4.0/)

**Code License:** [Apache License Version 2.0, January 2004](https://www.apache.org/licenses/LICENSE-2.0)


This is the repo of the [ESSLLI 2024] course on Large Language Models, Knowledge, and Reasoning.

- **Category:** Language and Computation (LaCo) - Introductory Course
- **Keywords:** Knowledge Representations, Description Logic, Knowledge Graphs, Large Language Models, Generative AI, Reasoning, Artificial Intelligence, Semantic Web, Neuro-symbolic Modelling

**Location:** Leuven, Belgium

**Dates:** 29th of July to 2nd of August, 2024

**Time:** 9:00 - 10:30 AM (Central European Time (UTC+01:00))


- [Plan](/plan)
- [Code and Data](/code)
- [References](/references)


See also: [Natural Language Processing Lab] ([NLP-Lab])


## Abstract

This course is intended to be an Introductory Course addressing Large Language Models, or in general Large Models (multi-modal) and Knowledge Representations for reasoning and semantic processing.

We address the following questions:

- What are knowledge representations? This is about ontologies, Knowledge Graphs, and semantic web approaches to handle, for example, Description, Logic representations, and reasoning.
- What are Large Language Models and, ultimately, Large Models? This mainly addresses so-called Generative AI, approaches to building and training models, and their application and limits when the input is unstructured text or visual information only.

How can LMs and computational semantics approaches be combined? This addresses general problems of LMs (e.g., hallucinations), and we discuss how symbolic (and also probabilistic) knowledge representations can be linked to LMs generating more reliable responses, summaries, and even pragmatic aspects like implicatures and presuppositions. We also discuss how LMs can be trained on knowledge and semantic representations to improve their reasoning capabilities.

This course is accompanied by extensive material, code, and instructions shared with students and the community, including hands-on access to the respective technologies. Depending on the audience, interest, and goals, we can adjust the level and content and design the course to include a discussion of state-of-the-art approaches to the generation of ontologies, taxonomies, and Knowledge Graph representations. This course might sound technologically challenging, but we can assure you that it is actually within the scope of undergraduate students and is certainly appropriate for interested graduate students coming with basic computation experience, knowledge of statistics, and interest in logic, semantics, and knowledge representations.



[ESSLLI 2024]: https://2024.esslli.eu/ "ESSLLI 2024"
[Damir Cavar]: http://damir.cavar.me/ "Damir Cavar"
[Dr. Damir Cavar]: https://luddy.indiana.edu/contact/profile/?Damir_Cavar "Damir Cavar"
[Python]: https://www.python.org/ "Python"
[Rust]: https://www.rust-lang.org/ "Rust Language"
[NLP]: https://en.wikipedia.org/wiki/Natural_language_processing "Natural Language Processing"
[Natural Language Processing]: https://en.wikipedia.org/wiki/Natural_language_processing "Natural Language Processing"
[AI]: https://en.wikipedia.org/wiki/Artificial_intelligence "Artificial Intelligence"
[Artificial Intelligence]: https://en.wikipedia.org/wiki/Artificial_intelligence "Artificial Intelligence"
[ML]: https://en.wikipedia.org/wiki/Machine_learning "Machine Learning"
[Machine Learning]: https://en.wikipedia.org/wiki/Machine_learning "Machine Learning"
[Natural Language Processing Lab]: https://nlp-lab.org/ "Natural Language Processing Lab"
[NLP-Lab]: https://nlp-lab.org/ "Natural Language Processing Lab"

